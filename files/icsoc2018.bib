@InProceedings{10.1007/978-3-030-03596-9_14,
author="da Silva Veith, Alexandre
and de Assun{\c{c}}{\~a}o, Marcos Dias
and Lef{\`e}vre, Laurent",
editor="Pahl, Claus
and Vukovic, Maja
and Yin, Jianwei
and Yu, Qi",
title="Latency-Aware Placement of Data Stream Analytics on Edge Computing",
booktitle="Service-Oriented Computing",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="215--229",
abstract="The interest in processing data events under stringent time constraints as they arrive has led to the emergence of architecture and engines for data stream processing. Edge computing, initially designed to minimize the latency of content delivered to mobile devices, can be used for executing certain stream processing operations. Moving operators from cloud to edge, however, is challenging as operator-placement decisions must consider the application requirements and the network capabilities. In this work, we introduce strategies to create placement configurations for data stream processing applications whose operator topologies follow series parallel graphs. We consider the operator characteristics and requirements to improve the response time of such applications. Results show that our strategies can improve the response time in upÂ to 50{\%} for application graphs comprising multiple forks and joins while transferring less data and better using the resources.",
isbn="978-3-030-03596-9"
}

