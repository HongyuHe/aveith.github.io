@ARTICLE{9281110,
  author={P. R. R. {De Souza} and K. J. {Matteussi} and A. D. S. {Veith} and B. F. {Zanchetta} and V. R. Q. {Leithardt} and Á. L. {Murciego} and E. P. {De Freitas} and J. C. S. D. {Anjos} and C. F. R. {Geyer}},
  journal={IEEE Access}, 
  title={Boosting Big Data Streaming Applications in Clouds With BurstFlow}, 
  year={2020},
  volume={8},
  number={},
  pages={219124-219136},
  abstract={The rapid growth of stream applications in financial markets, health care, education, social media, and sensor networks represents a remarkable milestone for data processing and analytic in recent years, leading to new challenges to handle Big Data in real-time. Traditionally, a single cloud infrastructure often holds the deployment of Stream Processing applications because it has extensive and adaptative virtual computing resources. Hence, data sources send data from distant and different locations of the cloud infrastructure, increasing the application latency. The cloud infrastructure may be geographically distributed and it requires to run a set of frameworks to handle communication. These frameworks often comprise a Message Queue System and a Stream Processing Framework. The frameworks explore Multi-Cloud deploying each service in a different cloud and communication via high latency network links. This creates challenges to meet real-time application requirements because the data streams have different and unpredictable latencies forcing cloud providers’ communication systems to adjust to the environment changes continually. Previous works explore static micro-batch demonstrating its potential to overcome communication issues. This paper introduces BurstFlow, a tool for enhancing communication across data sources located at the edges of the Internet and Big Data Stream Processing applications located in cloud infrastructures. BurstFlow introduces a strategy for adjusting the micro-batch sizes dynamically according to the time required for communication and computation. BurstFlow also presents an adaptive data partition policy for distributing incoming streams across available machines by considering memory and CPU capacities. The experiments use a real-world multi-cloud deployment showing that BurstFlow can reduce the execution time up to 77% when compared to the state-of-the-art solutions, improving CPU efficiency by up to 49%.},
  keywords={Big data;stream processing applications;multi cloud;micro-batches;data partition},
  doi={10.1109/ACCESS.2020.3042739},
  ISSN={2169-3536},
  month={},}
